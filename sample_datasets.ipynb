{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path as osp\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../NSCL-PyTorch-Release/')\n",
    "sys.path.insert(0, 'my_imp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_imp.data import gen_image_transform, gen_bbox_transform\n",
    "from my_imp.copied.scene_annotation import annotate_objects\n",
    "from my_imp.copied.program_translator import clevr_to_nsclseq, nsclseq_to_nsclqsseq\n",
    "import nltk\n",
    "\n",
    "\n",
    "from vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "\n",
    "ans_dict_json = 'data/clevr_sample_mod/CLEVR_built_dictionaries.json'\n",
    "\n",
    "train_ds_root = 'data/clevr_sample_mod/train/'\n",
    "image_root = 'data/clevr_sample_mod/train/images/'\n",
    "vocab_json = 'data/clevr_sample_mod/train/vocab.json'\n",
    "train_scenes_json = 'data/clevr_sample_mod/train/scenes.json'\n",
    "train_questions_json = 'data/clevr_sample_mod/train/questions.json'\n",
    "\n",
    "val_ds_root = 'data/clevr_sample_mod/val/'\n",
    "val_image_root = 'data/clevr_sample_mod/val/images/'\n",
    "val_vocab_json = 'data/clevr_sample_mod/val/vocab.json'\n",
    "val_scenes_json = 'data/clevr_sample_mod/val/scenes.json'\n",
    "val_questions_json = 'data/clevr_sample_mod/val/questions.json'\n",
    "\n",
    "dataset_args = {\n",
    "    'train': {\n",
    "        'scenes_json': train_scenes_json,\n",
    "        'questions_json': train_questions_json,\n",
    "        'image_root': image_root,\n",
    "        'vocab_json': vocab_json,\n",
    "    },\n",
    "    'val': {\n",
    "        'scenes_json': val_scenes_json,\n",
    "        'questions_json': val_questions_json,\n",
    "        'image_root': val_image_root,\n",
    "        'vocab_json': val_vocab_json,\n",
    "    },\n",
    "}\n",
    "\n",
    "image_transform = gen_image_transform(img_size)\n",
    "bbox_transform = gen_bbox_transform(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocab from: \"data/clevr_sample_mod/train/vocab.json\".\n",
      "Loading answers from: \"data/clevr_sample_mod/CLEVR_built_dictionaries.json\"\n",
      "==> using cached scenes: data/clevr_sample_mod/train/scenes_cache.pkl\n",
      "==> using cached questions: data/clevr_sample_mod/train/questions_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "class DatasetV2(Dataset):\n",
    "    def __init__(self,\n",
    "                 image_root,\n",
    "                 vocab_json,\n",
    "                 ans_dict_json,\n",
    "                 bbox_transform,\n",
    "                 scenes_json='',\n",
    "                 questions_json='',\n",
    "                 ds_root=None,\n",
    "                 image_transform=None,\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_root = image_root\n",
    "        self.image_transform = image_transform\n",
    "        self.bbox_transform = bbox_transform\n",
    "\n",
    "        print('Loading vocab from: \"{}\".'.format(vocab_json))\n",
    "        self.vocab = Vocab.from_json(vocab_json)\n",
    "        print('Loading answers from: \"{}\"'.format(ans_dict_json))\n",
    "        self.ans = Vocab.from_json(ans_dict_json)\n",
    "\n",
    "        cached_scenes = osp.join(\n",
    "            ds_root, 'scenes_cache.pkl') if ds_root else ''\n",
    "        if cached_scenes and osp.exists(cached_scenes):\n",
    "            print('==> using cached scenes: {}'.format(cached_scenes))\n",
    "            with open(cached_scenes, 'rb') as f:\n",
    "                self.scenes = pickle.load(f)\n",
    "        else:\n",
    "            with open(scenes_json, 'r') as f:\n",
    "                self.scenes = json.load(f)\n",
    "            self.prepare_scenes()\n",
    "            with open(cached_scenes, 'wb') as f:\n",
    "                pickle.dump(self.scenes, f)\n",
    "\n",
    "        cached_questions = osp.join(\n",
    "            ds_root, 'questions_cache.pkl') if ds_root else ''\n",
    "        if cached_questions and osp.exists(cached_questions):\n",
    "            print('==> using cached questions: {}'.format(cached_questions))\n",
    "            with open(cached_questions, 'rb') as f:\n",
    "                self.questions = pickle.load(f)\n",
    "        else:\n",
    "            with open(questions_json, 'r') as f:\n",
    "                self.questions = json.load(f)\n",
    "            self.prepare_questions()\n",
    "            with open(cached_questions, 'wb') as f:\n",
    "                pickle.dump(self.questions, f)\n",
    "\n",
    "    def prepare_scenes(self):\n",
    "        print('Preparing scenes')\n",
    "        if type(self.scenes) is list:\n",
    "            dummy_fp = osp.join(\n",
    "                self.image_root, self.scenes[0]['image_filename'])\n",
    "            scene_iter = self.scenes\n",
    "        elif type(self.scenes) is dict:\n",
    "            self.scenes = {int(key): val for key, val in self.scenes.items()}\n",
    "            dummy_fp = osp.join(self.image_root, list(\n",
    "                self.scenes.values())[0]['image_filename'])\n",
    "            scene_iter = self.scenes.values()\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Scenes type is '{type(self.scenes)}', expeceted 'list' or 'dict'\")\n",
    "        dummy_image = Image.open(dummy_fp).convert('RGB')\n",
    "        for i, scene in enumerate(scene_iter):\n",
    "            # scene = scenes['scenes'][i]\n",
    "            print(f'\\r{i + 1}/{len(self.scenes)}', end='')\n",
    "            objects = annotate_objects(scene)['objects']\n",
    "            # scene['objects_raw'] = scene['objects']\n",
    "            scene['objects'] = self.bbox_transform(dummy_image, objects)\n",
    "            scene['scene_size'] = len(scene['objects'])\n",
    "            scene['image_filename'] = osp.join(\n",
    "                self.image_root, scene['image_filename'])\n",
    "\n",
    "            del scene['relationships']\n",
    "            del scene['objects_detection']\n",
    "            del scene['directions']\n",
    "        print()\n",
    "\n",
    "    def prepare_questions(self):\n",
    "        print('\\nPreparing questions')\n",
    "        for i, q in enumerate(self.questions):\n",
    "            print(f'\\r{i + 1}/{len(self.questions)}', end='')\n",
    "            q['program_size'] = len(q['program'])\n",
    "            q['question_raw'] = q['question']\n",
    "            q['question'] = np.array(self.vocab.map_sequence(nltk.word_tokenize(q['question'].lower())), dtype='int32')\n",
    "            q['answer_raw'] = q['answer']\n",
    "            q['answer'] = self.ans.word2idx[q['answer']]\n",
    "            # q['program_raw'] = q['program']\n",
    "            # q['program_seq'] = clevr_to_nsclseq(q['program'])\n",
    "            program_seq = clevr_to_nsclseq(q['program'])\n",
    "            q['program_qsseq'] = nsclseq_to_nsclqsseq(program_seq)\n",
    "            q['question_type'] = program_seq[-1]['op']\n",
    "\n",
    "            del q['program']\n",
    "            del q['image_filename']\n",
    "\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # fd = self.questions[index]\n",
    "        # scene = self.scenes[fd['image_index']]\n",
    "\n",
    "        # image = Image.open(scene['image_filename']).convert('RGB')\n",
    "        # image = self.image_transform(image)\n",
    "\n",
    "        # Testing without vars because of memory leaks\n",
    "        return {\n",
    "            'image': self.image_transform(Image.open(self.scenes[self.questions[index]['image_index']]['image_filename']).convert('RGB')),\n",
    "            **self.questions[index],\n",
    "            'objects': self.scenes[self.questions[index]['image_index']]['objects'],\n",
    "            }\n",
    "\n",
    "    def _get_metainfo(self, index):\n",
    "        return {\n",
    "            'question': self.questions[index],\n",
    "            'scene': self.scenes[self.questions[index]['image_index']],\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "        \n",
    "ds = DatasetV2(\n",
    "    image_root=image_root,\n",
    "    vocab_json=vocab_json,\n",
    "    image_transform=image_transform,\n",
    "    bbox_transform=bbox_transform,\n",
    "    ds_root=train_ds_root,\n",
    "    scenes_json=train_scenes_json,\n",
    "    ans_dict_json=ans_dict_json,\n",
    "    questions_json=train_questions_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_imp.train import build_curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1608"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = build_curriculum(ds, 6)\n",
    "len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
